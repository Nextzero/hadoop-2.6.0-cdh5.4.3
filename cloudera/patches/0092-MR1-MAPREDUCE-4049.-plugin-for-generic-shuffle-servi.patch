From e2a28b9db13620076e37dcf50e8e99f44a1158bf Mon Sep 17 00:00:00 2001
From: Alejandro Abdelnur <tucu@cloudera.com>
Date: Tue, 23 Jul 2013 17:07:57 -0700
Subject: [PATCH 092/596] MR1: MAPREDUCE-4049. plugin for generic shuffle
 service. (avnerb via tucu)

  Reason: CDH-13249, backporting TT side of plugglable shuffle.
(cherry picked from commit fe6ce94d802b6e44befd04a690b29630aaea2ebb)

(cherry picked from commit 0ea6f9cc0eaf87c6c20597d1b8c402b8c134096e)
(cherry picked from commit cda5135a8be18098c41ffd8c857af45e58302b82)
(cherry picked from commit ae452022713ef504c8bd548e1f0a62b6e9f1fb19)
---
 .../src/mapred/mapred-default.xml                  |    9 +
 .../hadoop/mapred/ShuffleProviderPlugin.java       |   47 +++++
 .../org/apache/hadoop/mapred/TaskTracker.java      |   88 +++++++--
 .../apache/hadoop/mapred/TestShufflePlugin.java    |  204 ++++++++++++++++++++
 4 files changed, 336 insertions(+), 12 deletions(-)
 create mode 100644 hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java
 create mode 100644 hadoop-mapreduce1-project/src/test/org/apache/hadoop/mapred/TestShufflePlugin.java

diff --git a/hadoop-mapreduce1-project/src/mapred/mapred-default.xml b/hadoop-mapreduce1-project/src/mapred/mapred-default.xml
index b4f61dc..da64c89 100644
--- a/hadoop-mapreduce1-project/src/mapred/mapred-default.xml
+++ b/hadoop-mapreduce1-project/src/mapred/mapred-default.xml
@@ -1375,5 +1375,14 @@
     It defines the ShuffleConsumerPlugin implementation to use.
   </description>
 </property>
+
+<property>
+  <name>mapreduce.shuffle.provider.plugin.classes</name>
+  <value>org.apache.hadoop.mapred.TaskTracker$DefaultShuffleProvider</value>
+  <description>A comma-separated list of classes that should be loaded as ShuffleProviderPlugin(s).
+   A ShuffleProviderPlugin can serve shuffle requests from reducetasks.
+   Each class in the list must be an instance of org.apache.hadoop.mapred.ShuffleProviderPlugin.
+  </description>
+</property>
   
 </configuration>
diff --git a/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java b/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java
new file mode 100644
index 0000000..51154b7
--- /dev/null
+++ b/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/ShuffleProviderPlugin.java
@@ -0,0 +1,47 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+import org.apache.hadoop.classification.InterfaceAudience;
+import org.apache.hadoop.classification.InterfaceStability;
+
+/**
+ * This interface is implemented by objects that are able to answer shuffle requests which are
+ * sent from a matching Shuffle Consumer that lives in context of a ReduceTask object.
+ *
+ * ShuffleProviderPlugin object will be notified on the following events:
+ * initialize, destroy.
+ *
+ * NOTE: This interface is also used when loading 3rd party plugins at runtime
+ *
+ */
+@InterfaceAudience.LimitedPrivate("MapReduce")
+@InterfaceStability.Unstable
+public interface ShuffleProviderPlugin {
+  /**
+   * Do constructor work here.
+   * This method is invoked by the TaskTracker Constructor
+   */
+  public void initialize(TaskTracker taskTracker);
+
+  /**
+   * close and cleanup any resource, including threads and disk space.
+   * This method is invoked by TaskTracker.shutdown
+   */
+  public void destroy();
+}
diff --git a/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/TaskTracker.java b/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/TaskTracker.java
index f17d5eb..7739a1d 100644
--- a/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/TaskTracker.java
+++ b/hadoop-mapreduce1-project/src/mapred/org/apache/hadoop/mapred/TaskTracker.java
@@ -163,6 +163,9 @@
   private String shuffleScheme;
   private int shufflePort;
 
+  public static final String SHUFFLE_PROVIDER_PLUGIN_CLASSES = "mapreduce.shuffle.provider.plugin.classes";
+  final private ShuffleProviderPlugin shuffleProviderPlugin = new MultiShuffleProviderPlugin();
+
   static enum State {NORMAL, STALE, INTERRUPTED, DENIED}
 
   static final FsPermission LOCAL_DIR_PERMISSION =
@@ -282,6 +285,52 @@ synchronized void checkDirs(LocalFileSystem fs,
     }
   }
 
+  public static class DefaultShuffleProvider implements ShuffleProviderPlugin {
+    public void initialize(TaskTracker tt) {
+      tt.server.addInternalServlet("mapOutput", "/mapOutput", MapOutputServlet.class);
+    }
+
+    public void destroy() {
+    }
+  }
+
+  private static class MultiShuffleProviderPlugin implements ShuffleProviderPlugin {
+
+    private ShuffleProviderPlugin[] plugins;
+
+    public void initialize(TaskTracker tt) {
+      Configuration conf = tt.getJobConf();
+      Class<?>[] klasses = conf.getClasses(SHUFFLE_PROVIDER_PLUGIN_CLASSES, DefaultShuffleProvider.class);
+
+      plugins = new ShuffleProviderPlugin[klasses.length];
+      for (int i = 0; i < klasses.length; i++) {
+        try{
+          LOG.info(" Loading ShuffleProviderPlugin: " + klasses[i]);
+          plugins[i] =  (ShuffleProviderPlugin)ReflectionUtils.newInstance(klasses[i], conf);
+          plugins[i].initialize(tt);
+        }
+        catch(Throwable t) {
+          LOG.warn("Exception instantiating/initializing a ShuffleProviderPlugin: " + klasses[i], t);
+          plugins[i] =  null;
+        }
+      }
+    }
+
+    public void destroy() {
+      if (plugins != null) {
+          for (ShuffleProviderPlugin plugin : plugins) {
+            try {
+              if (plugin != null) {
+                plugin.destroy();
+              }
+            } catch (Throwable t) {
+              LOG.warn("Exception destroying a ShuffleProviderPlugin: " + plugin, t);
+            }
+          }
+        }
+      }
+    }
+
   private LocalStorage localStorage;
   private long lastCheckDirsTime;
   private int lastNumFailures;
@@ -735,7 +784,7 @@ static String getLocalSplitFile(String user, String jobid, String taskid) {
     + TaskTracker.LOCAL_SPLIT_FILE;
   }
 
-  static String getIntermediateOutputDir(String user, String jobid,
+  public static String getIntermediateOutputDir(String user, String jobid,
       String taskid) {
     return getLocalTaskDir(user, jobid, taskid) + Path.SEPARATOR
     + TaskTracker.OUTPUT;
@@ -1518,6 +1567,14 @@ private void launchTaskForJob(TaskInProgress tip, JobConf jobConf,
   public synchronized void shutdown() throws IOException, InterruptedException {
     shuttingDown = true;
     close();
+    if (this.shuffleProviderPlugin != null) {
+      try {
+        LOG.info("Shutting down shuffleProviderPlugin");
+        this.shuffleProviderPlugin.destroy();
+      } catch (Exception e) {
+        LOG.warn("Exception shutting down shuffleProviderPlugin", e);
+      }
+    }
     if (this.server != null) {
       try {
         LOG.info("Shutting down StatusHttpServer");
@@ -4011,9 +4068,22 @@ String getName() {
   }
   
   /**
+   * Get the specific job conf for a running job.
+   */
+  public JobConf getJobConf(JobID jobId) throws IOException {
+    synchronized (runningJobs) {
+      RunningJob rjob = runningJobs.get(jobId);
+      if (rjob == null) {
+        throw new IOException("Unknown job " + jobId + "!!");
+      }
+      return rjob.getJobConf();
+    }
+  }
+
+  /**
    * Get the default job conf for this tracker.
    */
-  JobConf getJobConf() {
+  public JobConf getJobConf() {
     return fConf;
   }
     
@@ -4159,16 +4229,10 @@ public void doGet(HttpServletRequest request,
         FileSystem rfs = ((LocalFileSystem)
             context.getAttribute("local.file.system")).getRaw();
 
-      String userName = null;
-      String runAsUserName = null;
-      synchronized (tracker.runningJobs) {
-        RunningJob rjob = tracker.runningJobs.get(JobID.forName(jobId));
-        if (rjob == null) {
-          throw new IOException("Unknown job " + jobId + "!!");
-        }
-        userName = rjob.jobConf.getUser();
-        runAsUserName = tracker.getTaskController().getRunAsUser(rjob.jobConf);
-      }
+      JobConf jobConf = tracker.getJobConf(JobID.forName(jobId));
+      String userName = jobConf.getUser();
+      String runAsUserName = tracker.getTaskController().getRunAsUser(jobConf);
+
       // Index file
       String intermediateOutputDir = TaskTracker.getIntermediateOutputDir(userName, jobId, mapId);
       String indexKey = intermediateOutputDir + "/file.out.index";
diff --git a/hadoop-mapreduce1-project/src/test/org/apache/hadoop/mapred/TestShufflePlugin.java b/hadoop-mapreduce1-project/src/test/org/apache/hadoop/mapred/TestShufflePlugin.java
new file mode 100644
index 0000000..5b3ebe0
--- /dev/null
+++ b/hadoop-mapreduce1-project/src/test/org/apache/hadoop/mapred/TestShufflePlugin.java
@@ -0,0 +1,204 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+
+import org.junit.Test;
+import static org.junit.Assert.*;
+import static org.mockito.Mockito.*;
+
+import org.apache.hadoop.mapred.Task.TaskReporter;
+import org.apache.hadoop.fs.LocalFileSystem;
+import java.io.IOException;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.hadoop.mapreduce.JobContext;
+
+/**
+ * A JUnit test for testing availability and accessibility of main API that is 
+ * needed for sub-classes of ShuffleProviderPlugin and ShuffleConsumerPlugin.
+ * The importance of this test is for preserving API with 3rd party plugins.
+ */
+public class TestShufflePlugin {
+
+  static class TestShuffleConsumerPlugin implements ShuffleConsumerPlugin {
+    @Override
+    public void init(ShuffleConsumerPlugin.Context context) {
+      // just verify that Context has kept its public interface
+      context.getReduceTask();
+      context.getJobConf();
+      context.getUmbilical();
+      context.getReporter();
+    }
+    @Override
+    public boolean fetchOutputs() throws IOException{
+      return true;
+    }
+    @Override
+    public Throwable getMergeThrowable(){
+      return null;
+    }
+    @Override
+    public RawKeyValueIterator createKVIterator() throws IOException{
+      return null;
+    }
+    @Override
+    public void close(){
+    }
+  }
+
+  @Test
+  /**
+   * A testing method instructing core hadoop to load an external 
+   * ShuffleConsumerPlugin
+   * as if it came from a 3rd party.
+   */
+  public void testConsumerPluginAbility() {
+
+    try{
+      // create JobConf with 
+      // mapreduce.job.shuffle.consumer.plugin=TestShuffleConsumerPlugin
+      JobConf jobConf = new JobConf();
+      jobConf.setClass(JobContext.SHUFFLE_CONSUMER_PLUGIN_ATTR,
+          TestShufflePlugin.TestShuffleConsumerPlugin.class,
+          ShuffleConsumerPlugin.class);
+
+      ShuffleConsumerPlugin shuffleConsumerPlugin = null;
+      Class<? extends ShuffleConsumerPlugin> clazz =
+          jobConf.getClass(JobContext.SHUFFLE_CONSUMER_PLUGIN_ATTR, null, 
+            ShuffleConsumerPlugin.class);
+      assertNotNull("Unable to get " + JobContext.SHUFFLE_CONSUMER_PLUGIN_ATTR,
+        clazz);
+
+      // load 3rd party plugin through core's factory method
+      shuffleConsumerPlugin = ReflectionUtils.newInstance(clazz, jobConf);
+      assertNotNull("Unable to load " + JobContext.SHUFFLE_CONSUMER_PLUGIN_ATTR, 
+        shuffleConsumerPlugin);
+    }
+    catch (Exception e) {
+      assertTrue("Threw exception:" + e, false);
+    }
+  }
+
+  static class TestShuffleProviderPlugin implements ShuffleProviderPlugin {
+    @Override
+    public void initialize(TaskTracker tt) {
+    }
+    @Override
+    public void destroy(){
+    }
+  }
+
+  @Test
+  /**
+   * A testing method instructing core hadoop to load an external 
+   * ShuffleConsumerPlugin
+   * as if it came from a 3rd party.
+   */
+  public void testProviderPluginAbility() {
+
+    try{
+      // create JobConf with 
+      // mapreduce.job.shuffle.provider.plugin=TestShuffleProviderPlugin
+      JobConf jobConf = new JobConf();
+      jobConf.setClass(TaskTracker.SHUFFLE_PROVIDER_PLUGIN_CLASSES,
+          TestShufflePlugin.TestShuffleProviderPlugin.class,
+          ShuffleProviderPlugin.class);
+
+      ShuffleProviderPlugin shuffleProviderPlugin = null;
+      Class<? extends ShuffleProviderPlugin> clazz =
+          jobConf.getClass(TaskTracker.SHUFFLE_PROVIDER_PLUGIN_CLASSES, null, 
+            ShuffleProviderPlugin.class);
+      assertNotNull("Unable to get " + 
+        TaskTracker.SHUFFLE_PROVIDER_PLUGIN_CLASSES, clazz);
+
+      // load 3rd party plugin through core's factory method
+      shuffleProviderPlugin = ReflectionUtils.newInstance(clazz, jobConf);
+      assertNotNull("Unable to load " +
+        TaskTracker.SHUFFLE_PROVIDER_PLUGIN_CLASSES, shuffleProviderPlugin);
+    }
+    catch (Exception e) {
+      assertTrue("Threw exception:" + e, false);
+    }
+  }
+
+  @Test
+  /**
+   * A method for testing availability and accessibility of API that is needed 
+   * for sub-classes of ShuffleProviderPlugin
+   */
+  public void testProvider() {
+    //mock creation
+    ShuffleProviderPlugin mockShuffleProvider = 
+      mock(ShuffleProviderPlugin.class);
+    TaskTracker mockTT = mock(TaskTracker.class);
+    TaskController mockTaskController = mock(TaskController.class);
+
+    mockShuffleProvider.initialize(mockTT);
+    mockShuffleProvider.destroy();
+    try {
+      mockTT.getJobConf();
+      mockTT.getJobConf(mock(JobID.class));
+      mockTT.getIntermediateOutputDir("","","");
+      mockTT.getTaskController();
+      mockTaskController.getRunAsUser(mock(JobConf.class));
+    }
+    catch (Exception e){
+      assertTrue("Threw exception:" + e, false);
+    }
+  }
+
+  @Test
+  /**
+   * A method for testing availability and accessibility of API that is
+   * needed for sub-classes of ShuffleConsumerPlugin
+   */
+  public void testConsumer() {
+    //mock creation
+    ShuffleConsumerPlugin mockShuffleConsumer = 
+      mock(ShuffleConsumerPlugin.class);
+    ReduceTask mockReduceTask = mock(ReduceTask.class);
+    JobConf mockJobConf = mock(JobConf.class);
+    TaskUmbilicalProtocol mockUmbilical = mock(TaskUmbilicalProtocol.class);
+    TaskReporter mockReporter = mock(TaskReporter.class);
+    LocalFileSystem mockLocalFileSystem = mock(LocalFileSystem.class);
+
+    mockReduceTask.getTaskID();
+    mockReduceTask.getJobID();
+    mockReduceTask.getNumMaps();
+    mockReduceTask.getPartition();
+    mockReduceTask.getJobFile();
+    mockReduceTask.getJvmContext();
+
+    mockReporter.progress();
+
+    try {
+      String [] dirs = mockJobConf.getLocalDirs();
+      ShuffleConsumerPlugin.Context context = 
+        new ShuffleConsumerPlugin.Context(mockUmbilical, mockJobConf, 
+          mockReporter, mockReduceTask);
+      mockShuffleConsumer.init(context);
+      mockShuffleConsumer.fetchOutputs();
+      mockShuffleConsumer.createKVIterator();
+      mockShuffleConsumer.close();
+    }
+    catch (Exception e){
+      assertTrue("Threw exception:" + e, false);
+    }
+  }
+}
-- 
1.7.9.5

