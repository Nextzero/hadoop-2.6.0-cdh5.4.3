From 1a455f01323ffaa16e6d9f1a3d46d9f385237560 Mon Sep 17 00:00:00 2001
From: Colin Patrick Mccabe <cmccabe@cloudera.com>
Date: Tue, 16 Dec 2014 17:05:27 -0800
Subject: [PATCH 430/596] HADOOP-11416. Move ChunkedArrayList into
 hadoop-common (cmccabe)

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java

(cherry picked from commit 4281c96e24739387bc2084f819c0176d0051a5e9)
(cherry picked from commit 89d6ac498adccbb9633c854f8f0e4c7ba9040bac)
---
 .../org/apache/hadoop/util/ChunkedArrayList.java   |  205 ++++++++++++++++++++
 .../apache/hadoop/util/TestChunkedArrayList.java   |  171 ++++++++++++++++
 .../hadoop/hdfs/server/namenode/FSDirectory.java   |    2 +-
 .../hdfs/server/namenode/FSEditLogLoader.java      |    2 +-
 .../hadoop/hdfs/server/namenode/FSNamesystem.java  |    2 +-
 .../apache/hadoop/hdfs/server/namenode/INode.java  |    2 +-
 .../apache/hadoop/hdfs/util/ChunkedArrayList.java  |  205 --------------------
 .../hadoop/hdfs/util/TestChunkedArrayList.java     |  171 ----------------
 8 files changed, 380 insertions(+), 380 deletions(-)
 create mode 100644 hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ChunkedArrayList.java
 create mode 100644 hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestChunkedArrayList.java
 delete mode 100644 hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/ChunkedArrayList.java
 delete mode 100644 hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/TestChunkedArrayList.java

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ChunkedArrayList.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ChunkedArrayList.java
new file mode 100644
index 0000000..84ddc32
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/ChunkedArrayList.java
@@ -0,0 +1,205 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.util;
+
+import java.util.AbstractList;
+import java.util.Iterator;
+import java.util.List;
+
+import org.apache.hadoop.classification.InterfaceAudience;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.Iterables;
+import com.google.common.collect.Lists;
+
+/**
+ * Simplified List implementation which stores elements as a list
+ * of chunks, each chunk having a maximum size. This improves over
+ * using an ArrayList in that creating a large list will never require
+ * a large amount of contiguous heap space -- thus reducing the likelihood
+ * of triggering a CMS compaction pause due to heap fragmentation.
+ * 
+ * The first chunks allocated are small, but each additional chunk is
+ * 50% larger than the previous, ramping up to a configurable maximum
+ * chunk size. Reasonable defaults are provided which should be a good
+ * balance between not making any large allocations while still retaining
+ * decent performance.
+ *
+ * This currently only supports a small subset of List operations --
+ * namely addition and iteration.
+ */
+@InterfaceAudience.Private
+public class ChunkedArrayList<T> extends AbstractList<T> {
+
+  /**
+   * The chunks which make up the full list.
+   */
+  private final List<List<T>> chunks = Lists.newArrayList();
+  
+  /**
+   * Cache of the last element in the 'chunks' array above.
+   * This speeds up the add operation measurably.
+   */
+  private List<T> lastChunk = null;
+
+  /**
+   * The capacity with which the last chunk was allocated.
+   */
+  private int lastChunkCapacity;
+  
+  /**
+   * The capacity of the first chunk to allocate in a cleared list.
+   */
+  private final int initialChunkCapacity;
+  
+  /**
+   * The maximum number of elements for any chunk.
+   */
+  private final int maxChunkSize;
+
+  /**
+   * Total number of elements in the list.
+   */
+  private int size;
+  
+  /**
+   * Default initial size is 6 elements, since typical minimum object
+   * size is 64 bytes, and this leaves enough space for the object
+   * header.
+   */
+  private static final int DEFAULT_INITIAL_CHUNK_CAPACITY = 6;
+  
+  /**
+   * Default max size is 8K elements - which, at 8 bytes per element
+   * should be about 64KB -- small enough to easily fit in contiguous
+   * free heap space even with a fair amount of fragmentation.
+   */
+  private static final int DEFAULT_MAX_CHUNK_SIZE = 8*1024;
+  
+
+  public ChunkedArrayList() {
+    this(DEFAULT_INITIAL_CHUNK_CAPACITY, DEFAULT_MAX_CHUNK_SIZE);
+  }
+
+  /**
+   * @param initialChunkCapacity the capacity of the first chunk to be
+   * allocated
+   * @param maxChunkSize the maximum size of any chunk allocated
+   */
+  public ChunkedArrayList(int initialChunkCapacity, int maxChunkSize) {
+    Preconditions.checkArgument(maxChunkSize >= initialChunkCapacity);
+    this.initialChunkCapacity = initialChunkCapacity;
+    this.maxChunkSize = maxChunkSize;
+  }
+
+  @Override
+  public Iterator<T> iterator() {
+    final Iterator<T> it = Iterables.concat(chunks).iterator();
+
+    return new Iterator<T>() {
+      @Override
+      public boolean hasNext() {
+        return it.hasNext();
+      }
+
+      @Override
+      public T next() {
+        return it.next();
+      }
+
+      @Override
+      public void remove() {
+        it.remove();
+        size--;
+      }
+    };
+  }
+
+  @Override
+  public boolean add(T e) {
+    if (size == Integer.MAX_VALUE) {
+      throw new RuntimeException("Can't add an additional element to the " +
+          "list; list already has INT_MAX elements.");
+    }
+    if (lastChunk == null) {
+      addChunk(initialChunkCapacity);
+    } else if (lastChunk.size() >= lastChunkCapacity) {
+      int newCapacity = lastChunkCapacity + (lastChunkCapacity >> 1);
+      addChunk(Math.min(newCapacity, maxChunkSize));
+    }
+    size++;
+    return lastChunk.add(e);
+  }
+
+  @Override
+  public void clear() {
+    chunks.clear();
+    lastChunk = null;
+    lastChunkCapacity = 0;
+    size = 0;
+  }
+  
+  private void addChunk(int capacity) {
+    lastChunk = Lists.newArrayListWithCapacity(capacity);
+    chunks.add(lastChunk);
+    lastChunkCapacity = capacity;
+  }
+
+  @Override
+  public boolean isEmpty() {
+    return size == 0;
+  }
+
+  @Override
+  public int size() {
+    return size;
+  }
+  
+  @VisibleForTesting
+  int getNumChunks() {
+    return chunks.size();
+  }
+  
+  @VisibleForTesting
+  int getMaxChunkSize() {
+    int size = 0;
+    for (List<T> chunk : chunks) {
+      size = Math.max(size, chunk.size());
+    }
+    return size;
+  }
+
+  @Override
+  public T get(int idx) {
+    if (idx < 0) {
+      throw new IndexOutOfBoundsException();
+    }
+    int base = 0;
+    Iterator<List<T>> it = chunks.iterator();
+    while (it.hasNext()) {
+      List<T> list = it.next();
+      int size = list.size();
+      if (idx < base + size) {
+        return list.get(idx - base);
+      }
+      base += size;
+    }
+    throw new IndexOutOfBoundsException();
+  }
+}
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestChunkedArrayList.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestChunkedArrayList.java
new file mode 100644
index 0000000..f8a2d49
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestChunkedArrayList.java
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.util;
+
+import static org.junit.Assert.*;
+
+import java.util.ArrayList;
+import java.util.Iterator;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import com.google.common.base.Stopwatch;
+
+public class TestChunkedArrayList {
+
+  @Test
+  public void testBasics() {
+    final int N_ELEMS = 100000;
+    ChunkedArrayList<Integer> l = new ChunkedArrayList<Integer>();
+    assertTrue(l.isEmpty());
+    // Insert a bunch of elements.
+    for (int i = 0; i < N_ELEMS; i++) {
+      l.add(i);
+    }
+    assertFalse(l.isEmpty());
+    assertEquals(N_ELEMS, l.size());
+
+    // Check that it got chunked.
+    assertTrue(l.getNumChunks() > 10);
+    assertEquals(8192, l.getMaxChunkSize());
+  }
+  
+  @Test
+  public void testIterator() {
+    ChunkedArrayList<Integer> l = new ChunkedArrayList<Integer>();
+    for (int i = 0; i < 30000; i++) {
+      l.add(i);
+    }
+    
+    int i = 0;
+    for (int fromList : l) {
+      assertEquals(i, fromList);
+      i++;
+    }
+  }
+  
+  @Test
+  public void testPerformance() {
+    String obj = "hello world";
+    
+    final int numElems = 1000000;
+    final int numTrials = 5;
+    
+    for (int trial = 0; trial < numTrials; trial++) {
+      System.gc();
+      {
+        ArrayList<String> arrayList = new ArrayList<String>();
+        Stopwatch sw = new Stopwatch();
+        sw.start();
+        for (int i = 0; i < numElems; i++) {
+          arrayList.add(obj);
+        }
+        System.out.println("       ArrayList " + sw.elapsedMillis());
+      }
+      
+      // test ChunkedArrayList
+      System.gc();
+      {
+        ChunkedArrayList<String> chunkedList = new ChunkedArrayList<String>();
+        Stopwatch sw = new Stopwatch();
+        sw.start();
+        for (int i = 0; i < numElems; i++) {
+          chunkedList.add(obj);
+        }
+        System.out.println("ChunkedArrayList " + sw.elapsedMillis());
+      }
+    }
+  }
+
+  @Test
+  public void testRemovals() throws Exception {
+    final int NUM_ELEMS = 100000;
+    ChunkedArrayList<Integer> list = new ChunkedArrayList<Integer>();
+    for (int i = 0; i < NUM_ELEMS; i++) {
+      list.add(i);
+    }
+
+    // Iterate through all list elements.
+    Iterator<Integer> iter = list.iterator();
+    for (int i = 0; i < NUM_ELEMS; i++) {
+      Assert.assertTrue(iter.hasNext());
+      Integer val = iter.next();
+      Assert.assertEquals(Integer.valueOf(i), val);
+    }
+    Assert.assertFalse(iter.hasNext());
+    Assert.assertEquals(NUM_ELEMS, list.size());
+
+    // Remove even elements.
+    iter = list.iterator();
+    for (int i = 0; i < NUM_ELEMS; i++) {
+      Assert.assertTrue(iter.hasNext());
+      Integer val = iter.next();
+      Assert.assertEquals(Integer.valueOf(i), val);
+      if (i % 2 == 0) {
+        iter.remove();
+      }
+    }
+    Assert.assertFalse(iter.hasNext());
+    Assert.assertEquals(NUM_ELEMS / 2, list.size());
+
+    // Iterate through all odd list elements.
+    iter = list.iterator();
+    for (int i = 0; i < NUM_ELEMS / 2; i++) {
+      Assert.assertTrue(iter.hasNext());
+      Integer val = iter.next();
+      Assert.assertEquals(Integer.valueOf(1 + (2 * i)), val);
+      iter.remove();
+    }
+    Assert.assertFalse(iter.hasNext());
+
+    // Check that list is now empty.
+    Assert.assertEquals(0, list.size());
+    Assert.assertTrue(list.isEmpty());
+    iter = list.iterator();
+    Assert.assertFalse(iter.hasNext());
+  }
+
+  @Test
+  public void testGet() throws Exception {
+    final int NUM_ELEMS = 100001;
+    ChunkedArrayList<Integer> list = new ChunkedArrayList<Integer>();
+    for (int i = 0; i < NUM_ELEMS; i++) {
+      list.add(i);
+    }
+
+    Assert.assertEquals(Integer.valueOf(100), list.get(100));
+    Assert.assertEquals(Integer.valueOf(1000), list.get(1000));
+    Assert.assertEquals(Integer.valueOf(10000), list.get(10000));
+    Assert.assertEquals(Integer.valueOf(100000), list.get(100000));
+
+    Iterator<Integer> iter = list.iterator();
+    iter.next();
+    iter.remove();
+    Assert.assertEquals(Integer.valueOf(1), list.get(0));
+
+    iter = list.iterator();
+    for (int i = 0; i < 500; i++) {
+      iter.next();
+    }
+    iter.remove();
+
+    Assert.assertEquals(Integer.valueOf(502), list.get(500));
+    Assert.assertEquals(Integer.valueOf(602), list.get(600));
+  }
+}
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
index 54e5101..37160da 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java
@@ -89,8 +89,8 @@
 import org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot;
 import org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot.Root;
 import org.apache.hadoop.hdfs.util.ByteArray;
-import org.apache.hadoop.hdfs.util.ChunkedArrayList;
 import org.apache.hadoop.hdfs.util.ReadOnlyList;
+import org.apache.hadoop.util.ChunkedArrayList;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Preconditions;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
index e9b911b..c6adff3 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java
@@ -95,8 +95,8 @@
 import org.apache.hadoop.hdfs.server.namenode.startupprogress.StartupProgress;
 import org.apache.hadoop.hdfs.server.namenode.startupprogress.StartupProgress.Counter;
 import org.apache.hadoop.hdfs.server.namenode.startupprogress.Step;
-import org.apache.hadoop.hdfs.util.ChunkedArrayList;
 import org.apache.hadoop.hdfs.util.Holder;
+import org.apache.hadoop.util.ChunkedArrayList;
 
 import com.google.common.base.Joiner;
 import com.google.common.base.Preconditions;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
index c1abe23..27dceab 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
@@ -263,7 +263,6 @@
 import org.apache.hadoop.hdfs.server.protocol.NamespaceInfo;
 import org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks;
 import org.apache.hadoop.hdfs.server.protocol.StorageReport;
-import org.apache.hadoop.hdfs.util.ChunkedArrayList;
 import org.apache.hadoop.io.IOUtils;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.ipc.RetriableException;
@@ -286,6 +285,7 @@
 import org.apache.hadoop.security.token.Token;
 import org.apache.hadoop.security.token.TokenIdentifier;
 import org.apache.hadoop.security.token.delegation.DelegationKey;
+import org.apache.hadoop.util.ChunkedArrayList;
 import org.apache.hadoop.util.Daemon;
 import org.apache.hadoop.util.DataChecksum;
 import org.apache.hadoop.util.ReflectionUtils;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java
index d652c9a..495145b 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INode.java
@@ -36,8 +36,8 @@
 import org.apache.hadoop.hdfs.server.namenode.INodeReference.DstReference;
 import org.apache.hadoop.hdfs.server.namenode.INodeReference.WithName;
 import org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot;
-import org.apache.hadoop.hdfs.util.ChunkedArrayList;
 import org.apache.hadoop.hdfs.util.Diff;
+import org.apache.hadoop.util.ChunkedArrayList;
 import org.apache.hadoop.util.StringUtils;
 
 import com.google.common.annotations.VisibleForTesting;
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/ChunkedArrayList.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/ChunkedArrayList.java
deleted file mode 100644
index b1f5862..0000000
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/ChunkedArrayList.java
+++ /dev/null
@@ -1,205 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.hdfs.util;
-
-import java.util.AbstractList;
-import java.util.Iterator;
-import java.util.List;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-
-import com.google.common.annotations.VisibleForTesting;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
-
-/**
- * Simplified List implementation which stores elements as a list
- * of chunks, each chunk having a maximum size. This improves over
- * using an ArrayList in that creating a large list will never require
- * a large amount of contiguous heap space -- thus reducing the likelihood
- * of triggering a CMS compaction pause due to heap fragmentation.
- * 
- * The first chunks allocated are small, but each additional chunk is
- * 50% larger than the previous, ramping up to a configurable maximum
- * chunk size. Reasonable defaults are provided which should be a good
- * balance between not making any large allocations while still retaining
- * decent performance.
- *
- * This currently only supports a small subset of List operations --
- * namely addition and iteration.
- */
-@InterfaceAudience.Private
-public class ChunkedArrayList<T> extends AbstractList<T> {
-
-  /**
-   * The chunks which make up the full list.
-   */
-  private final List<List<T>> chunks = Lists.newArrayList();
-  
-  /**
-   * Cache of the last element in the 'chunks' array above.
-   * This speeds up the add operation measurably.
-   */
-  private List<T> lastChunk = null;
-
-  /**
-   * The capacity with which the last chunk was allocated.
-   */
-  private int lastChunkCapacity;
-  
-  /**
-   * The capacity of the first chunk to allocate in a cleared list.
-   */
-  private final int initialChunkCapacity;
-  
-  /**
-   * The maximum number of elements for any chunk.
-   */
-  private final int maxChunkSize;
-
-  /**
-   * Total number of elements in the list.
-   */
-  private int size;
-  
-  /**
-   * Default initial size is 6 elements, since typical minimum object
-   * size is 64 bytes, and this leaves enough space for the object
-   * header.
-   */
-  private static final int DEFAULT_INITIAL_CHUNK_CAPACITY = 6;
-  
-  /**
-   * Default max size is 8K elements - which, at 8 bytes per element
-   * should be about 64KB -- small enough to easily fit in contiguous
-   * free heap space even with a fair amount of fragmentation.
-   */
-  private static final int DEFAULT_MAX_CHUNK_SIZE = 8*1024;
-  
-
-  public ChunkedArrayList() {
-    this(DEFAULT_INITIAL_CHUNK_CAPACITY, DEFAULT_MAX_CHUNK_SIZE);
-  }
-
-  /**
-   * @param initialChunkCapacity the capacity of the first chunk to be
-   * allocated
-   * @param maxChunkSize the maximum size of any chunk allocated
-   */
-  public ChunkedArrayList(int initialChunkCapacity, int maxChunkSize) {
-    Preconditions.checkArgument(maxChunkSize >= initialChunkCapacity);
-    this.initialChunkCapacity = initialChunkCapacity;
-    this.maxChunkSize = maxChunkSize;
-  }
-
-  @Override
-  public Iterator<T> iterator() {
-    final Iterator<T> it = Iterables.concat(chunks).iterator();
-
-    return new Iterator<T>() {
-      @Override
-      public boolean hasNext() {
-        return it.hasNext();
-      }
-
-      @Override
-      public T next() {
-        return it.next();
-      }
-
-      @Override
-      public void remove() {
-        it.remove();
-        size--;
-      }
-    };
-  }
-
-  @Override
-  public boolean add(T e) {
-    if (size == Integer.MAX_VALUE) {
-      throw new RuntimeException("Can't add an additional element to the " +
-          "list; list already has INT_MAX elements.");
-    }
-    if (lastChunk == null) {
-      addChunk(initialChunkCapacity);
-    } else if (lastChunk.size() >= lastChunkCapacity) {
-      int newCapacity = lastChunkCapacity + (lastChunkCapacity >> 1);
-      addChunk(Math.min(newCapacity, maxChunkSize));
-    }
-    size++;
-    return lastChunk.add(e);
-  }
-
-  @Override
-  public void clear() {
-    chunks.clear();
-    lastChunk = null;
-    lastChunkCapacity = 0;
-    size = 0;
-  }
-  
-  private void addChunk(int capacity) {
-    lastChunk = Lists.newArrayListWithCapacity(capacity);
-    chunks.add(lastChunk);
-    lastChunkCapacity = capacity;
-  }
-
-  @Override
-  public boolean isEmpty() {
-    return size == 0;
-  }
-
-  @Override
-  public int size() {
-    return size;
-  }
-  
-  @VisibleForTesting
-  int getNumChunks() {
-    return chunks.size();
-  }
-  
-  @VisibleForTesting
-  int getMaxChunkSize() {
-    int size = 0;
-    for (List<T> chunk : chunks) {
-      size = Math.max(size, chunk.size());
-    }
-    return size;
-  }
-
-  @Override
-  public T get(int idx) {
-    if (idx < 0) {
-      throw new IndexOutOfBoundsException();
-    }
-    int base = 0;
-    Iterator<List<T>> it = chunks.iterator();
-    while (it.hasNext()) {
-      List<T> list = it.next();
-      int size = list.size();
-      if (idx < base + size) {
-        return list.get(idx - base);
-      }
-      base += size;
-    }
-    throw new IndexOutOfBoundsException();
-  }
-}
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/TestChunkedArrayList.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/TestChunkedArrayList.java
deleted file mode 100644
index 5ae36e6..0000000
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/util/TestChunkedArrayList.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.hdfs.util;
-
-import static org.junit.Assert.*;
-
-import java.util.ArrayList;
-import java.util.Iterator;
-
-import org.junit.Assert;
-import org.junit.Test;
-
-import com.google.common.base.Stopwatch;
-
-public class TestChunkedArrayList {
-
-  @Test
-  public void testBasics() {
-    final int N_ELEMS = 100000;
-    ChunkedArrayList<Integer> l = new ChunkedArrayList<Integer>();
-    assertTrue(l.isEmpty());
-    // Insert a bunch of elements.
-    for (int i = 0; i < N_ELEMS; i++) {
-      l.add(i);
-    }
-    assertFalse(l.isEmpty());
-    assertEquals(N_ELEMS, l.size());
-
-    // Check that it got chunked.
-    assertTrue(l.getNumChunks() > 10);
-    assertEquals(8192, l.getMaxChunkSize());
-  }
-  
-  @Test
-  public void testIterator() {
-    ChunkedArrayList<Integer> l = new ChunkedArrayList<Integer>();
-    for (int i = 0; i < 30000; i++) {
-      l.add(i);
-    }
-    
-    int i = 0;
-    for (int fromList : l) {
-      assertEquals(i, fromList);
-      i++;
-    }
-  }
-  
-  @Test
-  public void testPerformance() {
-    String obj = "hello world";
-    
-    final int numElems = 1000000;
-    final int numTrials = 5;
-    
-    for (int trial = 0; trial < numTrials; trial++) {
-      System.gc();
-      {
-        ArrayList<String> arrayList = new ArrayList<String>();
-        Stopwatch sw = new Stopwatch();
-        sw.start();
-        for (int i = 0; i < numElems; i++) {
-          arrayList.add(obj);
-        }
-        System.out.println("       ArrayList " + sw.elapsedMillis());
-      }
-      
-      // test ChunkedArrayList
-      System.gc();
-      {
-        ChunkedArrayList<String> chunkedList = new ChunkedArrayList<String>();
-        Stopwatch sw = new Stopwatch();
-        sw.start();
-        for (int i = 0; i < numElems; i++) {
-          chunkedList.add(obj);
-        }
-        System.out.println("ChunkedArrayList " + sw.elapsedMillis());
-      }
-    }
-  }
-
-  @Test
-  public void testRemovals() throws Exception {
-    final int NUM_ELEMS = 100000;
-    ChunkedArrayList<Integer> list = new ChunkedArrayList<Integer>();
-    for (int i = 0; i < NUM_ELEMS; i++) {
-      list.add(i);
-    }
-
-    // Iterate through all list elements.
-    Iterator<Integer> iter = list.iterator();
-    for (int i = 0; i < NUM_ELEMS; i++) {
-      Assert.assertTrue(iter.hasNext());
-      Integer val = iter.next();
-      Assert.assertEquals(Integer.valueOf(i), val);
-    }
-    Assert.assertFalse(iter.hasNext());
-    Assert.assertEquals(NUM_ELEMS, list.size());
-
-    // Remove even elements.
-    iter = list.iterator();
-    for (int i = 0; i < NUM_ELEMS; i++) {
-      Assert.assertTrue(iter.hasNext());
-      Integer val = iter.next();
-      Assert.assertEquals(Integer.valueOf(i), val);
-      if (i % 2 == 0) {
-        iter.remove();
-      }
-    }
-    Assert.assertFalse(iter.hasNext());
-    Assert.assertEquals(NUM_ELEMS / 2, list.size());
-
-    // Iterate through all odd list elements.
-    iter = list.iterator();
-    for (int i = 0; i < NUM_ELEMS / 2; i++) {
-      Assert.assertTrue(iter.hasNext());
-      Integer val = iter.next();
-      Assert.assertEquals(Integer.valueOf(1 + (2 * i)), val);
-      iter.remove();
-    }
-    Assert.assertFalse(iter.hasNext());
-
-    // Check that list is now empty.
-    Assert.assertEquals(0, list.size());
-    Assert.assertTrue(list.isEmpty());
-    iter = list.iterator();
-    Assert.assertFalse(iter.hasNext());
-  }
-
-  @Test
-  public void testGet() throws Exception {
-    final int NUM_ELEMS = 100001;
-    ChunkedArrayList<Integer> list = new ChunkedArrayList<Integer>();
-    for (int i = 0; i < NUM_ELEMS; i++) {
-      list.add(i);
-    }
-
-    Assert.assertEquals(Integer.valueOf(100), list.get(100));
-    Assert.assertEquals(Integer.valueOf(1000), list.get(1000));
-    Assert.assertEquals(Integer.valueOf(10000), list.get(10000));
-    Assert.assertEquals(Integer.valueOf(100000), list.get(100000));
-
-    Iterator<Integer> iter = list.iterator();
-    iter.next();
-    iter.remove();
-    Assert.assertEquals(Integer.valueOf(1), list.get(0));
-
-    iter = list.iterator();
-    for (int i = 0; i < 500; i++) {
-      iter.next();
-    }
-    iter.remove();
-
-    Assert.assertEquals(Integer.valueOf(502), list.get(500));
-    Assert.assertEquals(Integer.valueOf(602), list.get(600));
-  }
-}
-- 
1.7.9.5

