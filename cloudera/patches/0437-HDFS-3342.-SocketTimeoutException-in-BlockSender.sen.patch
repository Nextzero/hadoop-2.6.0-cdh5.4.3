From 12531a2746935040a031180bf8500480ffe33aac Mon Sep 17 00:00:00 2001
From: Andrew Wang <wang@apache.org>
Date: Thu, 30 Oct 2014 11:03:13 -0700
Subject: [PATCH 437/596] HDFS-3342. SocketTimeoutException in
 BlockSender.sendChunks could have a better error
 message. Contributed by Yongjun Zhang.

(cherry picked from commit 16c0f04c50822a39610e34e0715d3d4a44be5a5f)

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt
---
 .../hadoop/hdfs/server/datanode/BlockSender.java   |    7 ++-----
 .../hadoop/hdfs/server/datanode/DataXceiver.java   |   16 ++++++++++++++--
 2 files changed, 16 insertions(+), 7 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java
index 94a730e..76637d5 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockSender.java
@@ -581,12 +581,9 @@ private int sendPacket(ByteBuffer pkt, int maxChunks, OutputStream out,
          * writing to client timed out.  This happens if the client reads
          * part of a block and then decides not to read the rest (but leaves
          * the socket open).
+         * 
+         * Reporting of this case is done in DataXceiver#run
          */
-        if (LOG.isTraceEnabled()) {
-          LOG.trace("Failed to send data:", e);
-        } else {
-          LOG.info("Failed to send data: " + e);
-        }
       } else {
         /* Exception while writing to the client. Connection closure from
          * the other end is mostly the case and we do not care much about
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java
index 08f137c..195c12b 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java
@@ -39,6 +39,7 @@
 import java.net.InetSocketAddress;
 import java.net.Socket;
 import java.net.SocketException;
+import java.net.SocketTimeoutException;
 import java.nio.channels.ClosedChannelException;
 import java.security.MessageDigest;
 import java.util.Arrays;
@@ -254,6 +255,15 @@ public void run() {
         } else {
           LOG.info(s + "; " + t);
         }
+      } else if (op == Op.READ_BLOCK && t instanceof SocketTimeoutException) {
+        String s1 =
+            "Likely the client has stopped reading, disconnecting it";
+        s1 += " (" + s + ")";
+        if (LOG.isTraceEnabled()) {
+          LOG.trace(s1, t);
+        } else {
+          LOG.info(s1 + "; " + t);          
+        }
       } else {
         LOG.error(s, t);
       }
@@ -534,9 +544,11 @@ public void readBlock(final ExtendedBlock block,
       /* What exactly should we do here?
        * Earlier version shutdown() datanode if there is disk error.
        */
-      LOG.warn(dnR + ":Got exception while serving " + block + " to "
+      if (!(ioe instanceof SocketTimeoutException)) {
+        LOG.warn(dnR + ":Got exception while serving " + block + " to "
           + remoteAddress, ioe);
-      datanode.metrics.incrDatanodeNetworkErrors();
+        datanode.metrics.incrDatanodeNetworkErrors();
+      }
       throw ioe;
     } finally {
       IOUtils.closeStream(blockSender);
-- 
1.7.9.5

